---
title: "R PROJECT | Clustering, linear regression and logistic regression"
author: "Hadrien Pistre"
date: 2022-05-11
categories: ["R Projects"]
tags: ["R", "Clustering", "Linear regression", "Logistic regression"]
---

I performed this analysis on a dataset containing information about users of <a href="https://www.bbc.co.uk/iplayer" target="_blank">BBC's iPLAYER</a> streaming service. This analysis was done during the elective "Data Mining for Business Intelligence" at <a href="https://www.london.edu/" target="_blank">London Business School</a> taught by <a href="https://www.london.edu/faculty-and-research/faculty-profiles/s/savva-n" target="_blank">Prof. Nicos Savva</a>, <a href="https://www.london.edu/faculty-and-research/faculty-profiles/k/kostis-christodoulou" target="_blank">Prof. Kostis Christodoulou</a> and <a href="https://www.london.edu/faculty-and-research/faculty-profiles/e/ekaterina-abramova" target="_blank">Prof. Ekaterina Abramova</a>.

![bbc](https://www.hadrienpistre.com/bbc.jpg)
*Image source: <a href="https://dla-architecture.co.uk/projects/bbc-building-leeds/" target="_blank">dla-architecture.co.uk</a>*


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

**Used packages:**
```{r libraries, cache=TRUE}
library(rsample)     
library(dplyr)       
library(rpart)       
library(rpart.plot)  
library(ipred)       
library(caret)       
library(randomForest)
library(tidyverse)  
library(fastDummies)
library(readxl)
library(janitor)
library(e1071)
library(caTools)
library(class)
library(tokenizers)
library(tidytext)
library(PRROC)
library(lubridate)
library(writexl)
library(ggthemes)
library(GGally)
library(factoextra)
library(cluster)
library(gridExtra)
library(parameters)
library(see)
```

## 0. Data cleaning

```{r data exploration and preparation, echo=TRUE, warning=FALSE, message=FALSE, error=FALSE, cache = TRUE}
#load the data from lending club
iplayer_data_raw <- read_csv((here::here("C:/Users/hadri/Desktop/R Folder/website/content/data/iplayer_data_sample.csv")))

#check features of iplayer raw data
names(iplayer_data_raw)

#check values of iplayer raw data
# str(iplayer_data_raw)

#inspect NAs
iplayer_data_raw_na <- iplayer_data_raw %>% 
  filter(is.na(program_id))
head(iplayer_data_raw_na)

#remove NAs
iplayer_data_raw_no_nas <- iplayer_data_raw %>%
  filter(!is.na(program_id))
head(iplayer_data_raw_no_nas)

#create a new column programme_duration_min and convert program duration to minutes
res <- hms(iplayer_data_raw_no_nas$programme_duration)        # format to 'hours:minutes:seconds'
iplayer_data_raw_no_nas$programme_duration_min <- hour(res)*60 + minute(res)

#delete all programs with duration less than 0.5 minutes
iplayer_data_raw_no_nas <- iplayer_data_raw_no_nas %>%
  filter(!iplayer_data_raw_no_nas$programme_duration_min < 0.5)

#create a new column time_viewed_min and convert the time_view to minutes (1 minute = 60,000 miliseconds)
iplayer_data_raw_no_nas$time_viewed_min <- iplayer_data_raw_no_nas$time_viewed / 60000

#delete time_viewed< 5 seconds (5 seconds = 0.0833 minute)
iplayer_data_raw_no_nas <- iplayer_data_raw_no_nas %>%
  filter(!iplayer_data_raw_no_nas$programme_duration_min < 0.0833)

#check if time watched is greater than duration
iplayer_data_raw_no_nas$time_viewed_greater_than_dur = ifelse(iplayer_data_raw_no_nas$time_viewed_min > iplayer_data_raw_no_nas$programme_duration_min,1,0)

#create a new variable called “time_viewed_min_enriched" and set it equal to the minimum of duration and time viewed in minutes
iplayer_data_raw_no_nas$time_viewed_min_enriched <- with(iplayer_data_raw_no_nas, pmin(programme_duration_min, time_viewed_min))

#create a variable “% watched” that calculates the proportion of a show watcheds
iplayer_data_raw_no_nas$percent_watched <- (iplayer_data_raw_no_nas$time_viewed_min_enriched/iplayer_data_raw_no_nas$programme_duration_min)*100

#create a dummy variable called “True_Engagement” that takes the value 1 if time watched is at least 60% of the show’s duration or at least 20 minutes, and 0 otherwise
iplayer_data_raw_no_nas$true_engagement <- ifelse(iplayer_data_raw_no_nas$percent_watched > 60 | iplayer_data_raw_no_nas$time_viewed_min > 20,1,0)

#create date view and time view
iplayer_data_raw_no_nas[c("date_viewed", "time_viewed")] <- str_split_fixed(iplayer_data_raw_no_nas$start_date_time, " ", 2)

#create a month_of_the_year variable
iplayer_data_raw_no_nas$month_of_the_year <- substring(iplayer_data_raw_no_nas$date_viewed, 6, 7)

#create a day_of_week_viewed variable
iplayer_data_raw_no_nas$day_of_week_viewed <- substring(iplayer_data_raw_no_nas$date_viewed, 9, 10)


#create a weekend dummy variable
iplayer_data_raw_no_nas$month_and_day <- paste(iplayer_data_raw_no_nas$month_of_the_year,iplayer_data_raw_no_nas$day_of_week_viewed)

iplayer_data_raw_no_nas$weekend_dummy <- ifelse(iplayer_data_raw_no_nas$month_and_day == "01 01" | iplayer_data_raw_no_nas$month_and_day == "01 01" | iplayer_data_raw_no_nas$month_and_day == "01 07" | iplayer_data_raw_no_nas$month_and_day == "01 08" | iplayer_data_raw_no_nas$month_and_day == "01 14" | iplayer_data_raw_no_nas$month_and_day == "01 15" | iplayer_data_raw_no_nas$month_and_day == "01 21" | iplayer_data_raw_no_nas$month_and_day == "01 22" | iplayer_data_raw_no_nas$month_and_day == "01 28" | iplayer_data_raw_no_nas$month_and_day == "01 29" |
                                                iplayer_data_raw_no_nas$month_and_day == "02 04" | iplayer_data_raw_no_nas$month_and_day == "02 05" | iplayer_data_raw_no_nas$month_and_day == "02 11" | iplayer_data_raw_no_nas$month_and_day == "02 12" | iplayer_data_raw_no_nas$month_and_day == "02 18" | iplayer_data_raw_no_nas$month_and_day == "02 19" | iplayer_data_raw_no_nas$month_and_day == "02 25" | iplayer_data_raw_no_nas$month_and_day == "02 26"
                                                ,1,0)

#create time-of-day variable that takes the value “N” if the viewing occurs between 10pm and 6am, “D” if the viewing occurs between 6am and 2pm, and “E” otherwise
iplayer_data_raw_no_nas$hour_viewed <- substring(iplayer_data_raw_no_nas$time_viewed, 1, 2)
iplayer_data_raw_no_nas$time_of_day <- ifelse(iplayer_data_raw_no_nas$hour_viewed == 22,"N",ifelse(iplayer_data_raw_no_nas$hour_viewed == 23,"N",ifelse(iplayer_data_raw_no_nas$hour_viewed == 00,"N",ifelse(iplayer_data_raw_no_nas$hour_viewed == 01,"N",ifelse(iplayer_data_raw_no_nas$hour_viewed == 02,"N",ifelse(iplayer_data_raw_no_nas$hour_viewed == 03,"N",ifelse(iplayer_data_raw_no_nas$hour_viewed == 04,"N",ifelse(iplayer_data_raw_no_nas$hour_viewed == 05,"N",ifelse(iplayer_data_raw_no_nas$hour_viewed == 06,"D",ifelse(iplayer_data_raw_no_nas$hour_viewed == 07,"D",ifelse(iplayer_data_raw_no_nas$hour_viewed == 08,"D",ifelse(iplayer_data_raw_no_nas$hour_viewed == 09,"D",ifelse(iplayer_data_raw_no_nas$hour_viewed == 10,"D",ifelse(iplayer_data_raw_no_nas$hour_viewed == 11,"D",ifelse(iplayer_data_raw_no_nas$hour_viewed == 12,"D",ifelse(iplayer_data_raw_no_nas$hour_viewed == 13,"D","E"))))))))))))))))

# write_xlsx(iplayer_data_raw_no_nas,"C:\\Users\\hadri\\Desktop\\iplayer_data_raw_no_nas.xlsx")
```


## 1. Supply and demand

We create two stacked bar charts to compare the supply and demand of programs and time viewed

```{r supply and demand, echo=TRUE, warning=FALSE, message=FALSE, error=FALSE, cache = TRUE}

iplayer_data_raw_no_nas_jan <- filter(iplayer_data_raw_no_nas, month_of_the_year == "01")

#minutes demanded by genre
demand_by_genre_mins <- iplayer_data_raw_no_nas_jan %>%
  group_by(genre) %>% 
  summarize(sum(time_viewed_min_enriched))

#number of users by genre
demand_by_genre_users <- iplayer_data_raw_no_nas_jan %>%
  group_by(genre) %>% 
  summarise(count = n_distinct(user_id))

#minutes supplied by genre
supply_by_genre_minutes <- iplayer_data_raw_no_nas_jan %>%
  group_by(genre) %>% 
  summarize(sum(programme_duration_min))

#programs supplied by genre
supply_by_genre_programs <- iplayer_data_raw_no_nas_jan %>%
  group_by(genre) %>% 
  summarise(count = n_distinct(program_id))

#create a table with supply and demand
supply_vs_demand <- data.frame(cbind(demand_by_genre_mins$genre,demand_by_genre_mins$`sum(time_viewed_min_enriched)`,demand_by_genre_users$count,supply_by_genre_minutes$`sum(programme_duration_min)`,supply_by_genre_programs$count))
names(supply_vs_demand)[1:5] <- c("genre","demand_minutes","demand_num_of_users","supply_minutes","supply_num_of_programs")
supply_vs_demand[2:5] <- lapply(supply_vs_demand[2:5], as.numeric)
supply_vs_demand$demand_minutes <- round(supply_vs_demand$demand_minutes,0)

#clear the NAs
supply_vs_demand <- subset(supply_vs_demand, genre!="N/A")

#create the difference of supply and demand for our stacked bar chart
supply_vs_demand$supply_minus_demand_minutes <- supply_vs_demand$supply_minutes - supply_vs_demand$demand_minutes

#pivot longer to create the bar chart
supply_vs_demand_long <- supply_vs_demand %>% 
  pivot_longer(
    cols = c(2:6),
    names_to = "type", 
    values_to = "values"
  )

#divide by 1000 for better readability
supply_vs_demand_long$values_000 <- supply_vs_demand_long$values/1000

head(supply_vs_demand_long)

#add a Z to put the demanded minutes below in our stacked bar chart
supply_vs_demand_long$type <- recode(supply_vs_demand_long$type,"demand_minutes" = "zdemand_minutes")

#create the bar chart
supply_vs_demand_long_minutes <- filter(supply_vs_demand_long, type == "supply_minus_demand_minutes" |  type == "zdemand_minutes")
ggplot(supply_vs_demand_long_minutes, aes(x = reorder(genre, desc(values_000)), y = values_000, fill = type))+
  geom_col() +
  scale_fill_discrete(labels = c("Minutes supplied - Minutes viewed", "Minutes viewed"))+
  theme_bw() +
  theme(legend.position = "bottom") +
  labs (
      title = "Minutes viewed vs Minutes supplied minus Minutes viewed",
      x     = "Genre",
      y     = "Minutes (000s)",
      fill = "Legend")

#create a side-by-side bar chart
supply_vs_demand_long_minutes <- filter(supply_vs_demand_long, type == "demand_num_of_users" |  type == "supply_num_of_programs")
ggplot(supply_vs_demand_long_minutes, aes(x = reorder(genre, desc(values)), y = values, fill = type))+
  geom_col(position = "dodge") +
  scale_fill_discrete(labels = c("Number of users", "Number of programs"))+
  theme_bw() +
  theme(legend.position = "bottom") +
  labs (
      title = "Number of users vs Number of programs",
      x     = "Genre",
      y     = "Number",
      fill = "Legend")

```

## 2. Customer segmentation analysis

### 2.1. We create several variables and then create clusters based on those variables

```{r creation of variables, echo=TRUE, warning=FALSE, message=FALSE, error=FALSE, cache = TRUE}

#create dummies
iplayer_data_raw_no_nas_jan_dummied <- iplayer_data_raw_no_nas_jan[!grepl("N/A", iplayer_data_raw_no_nas_jan$genre),]
iplayer_data_raw_no_nas_jan_dummied <- dummy_cols(iplayer_data_raw_no_nas_jan_dummied, select_columns = c('time_of_day','genre'))
iplayer_data_raw_no_nas_jan_dummied <- clean_names(iplayer_data_raw_no_nas_jan_dummied)

#total number of shows watched
shows_by_user <- iplayer_data_raw_no_nas_jan_dummied %>%
  group_by(user_id) %>% 
  summarise(count = n_distinct(program_id))
names(shows_by_user)[2] <- "shows_watched"

#total time spent watching shows on iPlayer
time_by_user <- iplayer_data_raw_no_nas_jan_dummied %>%
  group_by(user_id) %>% 
  summarize(sum(time_viewed_min_enriched))
names(time_by_user)[2] <- "time_viewed_enriched"

#number of shows watched during the weekend
week_end_dummy_by_user <- iplayer_data_raw_no_nas_jan_dummied %>%
  group_by(user_id) %>% 
  summarize(sum(weekend_dummy))
names(week_end_dummy_by_user)[2] <- "count_of_week_end_days"

#number of shows that were watch at least at 60% by user
engagement_by_user <- iplayer_data_raw_no_nas_jan_dummied %>%
  group_by(user_id) %>% 
  summarize(sum(true_engagement))
names(engagement_by_user)[2] <- "true_engagement"

#number of shows watched during day time
D_by_user <- iplayer_data_raw_no_nas_jan_dummied %>%
  group_by(user_id) %>% 
  summarize(sum(time_of_day_d))
names(D_by_user)[2] <- "count_of_D"

#number of shows watched in the evening
E_by_user <- iplayer_data_raw_no_nas_jan_dummied %>%
  group_by(user_id) %>% 
  summarize(sum(time_of_day_e))
names(E_by_user)[2] <- "count_of_E"

#number of shows watched in the night
N_by_user <- iplayer_data_raw_no_nas_jan_dummied %>%
  group_by(user_id) %>% 
  summarize(sum(time_of_day_n))
names(N_by_user)[2] <- "count_of_N"

#number of children shows watched
children_by_user <- iplayer_data_raw_no_nas_jan_dummied %>%
  group_by(user_id) %>% 
  summarize(sum(genre_childrens))
names(children_by_user)[2] <- "count_of_children"

#number of comedy shows watched
comedy_by_user <- iplayer_data_raw_no_nas_jan_dummied %>%
  group_by(user_id) %>% 
  summarize(sum(genre_comedy))
names(comedy_by_user)[2] <- "count_of_comedy"

#number of drama shows watched
drama_by_user <- iplayer_data_raw_no_nas_jan_dummied %>%
  group_by(user_id) %>% 
  summarize(sum(genre_drama))
names(drama_by_user)[2] <- "count_of_drama"

#number of entertainment shows watched
entertainment_by_user <- iplayer_data_raw_no_nas_jan_dummied %>%
  group_by(user_id) %>% 
  summarize(sum(genre_entertainment))
names(entertainment_by_user)[2] <- "count_of_entertainment"

#number of factual shows watched
factual_by_user <- iplayer_data_raw_no_nas_jan_dummied %>%
  group_by(user_id) %>% 
  summarize(sum(genre_factual))
names(factual_by_user)[2] <- "count_of_factual"

#number of learning shows watched
learning_by_user <- iplayer_data_raw_no_nas_jan_dummied %>%
  group_by(user_id) %>% 
  summarize(sum(genre_learning))
names(learning_by_user)[2] <- "count_of_learning"

#number of music shows watched
music_by_user <- iplayer_data_raw_no_nas_jan_dummied %>%
  group_by(user_id) %>% 
  summarize(sum(genre_music))
names(music_by_user)[2] <- "count_of_music"

#number of news shows watched
news_by_user <- iplayer_data_raw_no_nas_jan_dummied %>%
  group_by(user_id) %>% 
  summarize(sum(genre_news))
names(news_by_user)[2] <- "count_of_news"

#number of religion and ethics shows watched
religion_ethics_by_user <- iplayer_data_raw_no_nas_jan_dummied %>%
  group_by(user_id) %>% 
  summarize(sum(genre_religion_ethics))
names(religion_ethics_by_user)[2] <- "count_of_religion"

#number of sport shows watched
sport_by_user <- iplayer_data_raw_no_nas_jan_dummied %>%
  group_by(user_id) %>% 
  summarize(sum(genre_sport))
names(sport_by_user)[2] <- "count_of_sport"

#number of weather shows watched
weather_by_user <- iplayer_data_raw_no_nas_jan_dummied %>%
  group_by(user_id) %>% 
  summarize(sum(genre_weather))
names(weather_by_user)[2] <- "count_of_weather"

#bind all the variables we created together
proportions <- cbind(shows_by_user,time_by_user$time_viewed_enriched,week_end_dummy_by_user$count_of_week_end_days,engagement_by_user$true_engagement,D_by_user$count_of_D,E_by_user$count_of_E,N_by_user$count_of_N,children_by_user$count_of_children,comedy_by_user$count_of_comedy,drama_by_user$count_of_drama,entertainment_by_user$count_of_entertainment,factual_by_user$count_of_factual,learning_by_user$count_of_learning,music_by_user$count_of_music,news_by_user$count_of_news,religion_ethics_by_user$count_of_religion,sport_by_user$count_of_sport,weather_by_user$count_of_weather)

#rename the columns
names(proportions) <- c("user_id","shows_watched","time_viewed_enriched","count_of_week_end_days","true_engagement","count_of_D","count_of_E","count_of_N","count_of_children","count_of_comedy","count_of_drama","count_of_entertainment","count_of_factual","count_of_learning","count_of_music","count_of_news","count_of_religion","count_of_sport","count_of_weather")

#create the proportions
proportions$prop_watched_during_weekend <- 1 - proportions$count_of_week_end_days / proportions$shows_watched
proportions$prop_of_engagement <- proportions$true_engagement / proportions$shows_watched
proportions$prop_of_D <- proportions$count_of_D / proportions$shows_watched
proportions$prop_of_E <- proportions$count_of_E / proportions$shows_watched
proportions$prop_of_N <- proportions$count_of_N / proportions$shows_watched
proportions$prop_of_children <- proportions$count_of_children / proportions$shows_watched
proportions$prop_of_comedy <- proportions$count_of_comedy / proportions$shows_watched
proportions$prop_of_drama <- proportions$count_of_drama / proportions$shows_watched
proportions$prop_of_entertainment <- proportions$count_of_entertainment / proportions$shows_watched
proportions$prop_of_factual <- proportions$count_of_factual / proportions$shows_watched
proportions$prop_of_learning <- proportions$count_of_learning / proportions$shows_watched
proportions$prop_of_music <- proportions$count_of_music / proportions$shows_watched
proportions$prop_of_news <- proportions$count_of_news / proportions$shows_watched
proportions$prop_of_religion <- proportions$count_of_religion / proportions$shows_watched
proportions$prop_of_sport <- proportions$count_of_sport / proportions$shows_watched
proportions$prop_of_weather <- proportions$count_of_weather / proportions$shows_watched

#clean the proportions
proportions$prop_watched_during_weekend <- ifelse(proportions$prop_watched_during_weekend>1,1,proportions$prop_watched_during_weekend)
proportions$prop_watched_during_weekend <- ifelse(proportions$prop_watched_during_weekend<0,0,proportions$prop_watched_during_weekend)

proportions$prop_of_engagement <- ifelse(proportions$prop_of_engagement>1,1,proportions$prop_of_engagement)
proportions$prop_of_engagement <- ifelse(proportions$prop_of_engagement<0,0,proportions$prop_of_engagement)

proportions$prop_of_D <- ifelse(proportions$prop_of_D>1,1,proportions$prop_of_D)
proportions$prop_of_D <- ifelse(proportions$prop_of_D<0,0,proportions$prop_of_D)

proportions$prop_of_E <- ifelse(proportions$prop_of_E>1,1,proportions$prop_of_E)
proportions$prop_of_E <- ifelse(proportions$prop_of_E<0,0,proportions$prop_of_E)

proportions$prop_of_N <- ifelse(proportions$prop_of_N>1,1,proportions$prop_of_N)
proportions$prop_of_N <- ifelse(proportions$prop_of_N<0,0,proportions$prop_of_N)

proportions$prop_of_children <- ifelse(proportions$prop_of_children>1,1,proportions$prop_of_children)
proportions$prop_of_children <- ifelse(proportions$prop_of_children<0,0,proportions$prop_of_children)

proportions$prop_of_comedy <- ifelse(proportions$prop_of_comedy>1,1,proportions$prop_of_comedy)
proportions$prop_of_comedy <- ifelse(proportions$prop_of_comedy<0,0,proportions$prop_of_comedy)

proportions$prop_of_drama <- ifelse(proportions$prop_of_drama>1,1,proportions$prop_of_drama)
proportions$prop_of_drama <- ifelse(proportions$prop_of_drama<0,0,proportions$prop_of_drama)

proportions$prop_of_entertainment <- ifelse(proportions$prop_of_entertainment>1,1,proportions$prop_of_entertainment)
proportions$prop_of_entertainment <- ifelse(proportions$prop_of_entertainment<0,0,proportions$prop_of_entertainment)

proportions$prop_of_factual <- ifelse(proportions$prop_of_factual>1,1,proportions$prop_of_factual)
proportions$prop_of_factual <- ifelse(proportions$prop_of_factual<0,0,proportions$prop_of_factual)

proportions$prop_of_learning <- ifelse(proportions$prop_of_learning>1,1,proportions$prop_of_learning)
proportions$prop_of_learning <- ifelse(proportions$prop_of_learning<0,0,proportions$prop_of_learning)

proportions$prop_of_music <- ifelse(proportions$prop_of_music>1,1,proportions$prop_of_music)
proportions$prop_of_music <- ifelse(proportions$prop_of_music<0,0,proportions$prop_of_music)

proportions$prop_of_news <- ifelse(proportions$prop_of_news>1,1,proportions$prop_of_news)
proportions$prop_of_news <- ifelse(proportions$prop_of_news<0,0,proportions$prop_of_news)

proportions$prop_of_religion <- ifelse(proportions$prop_of_religion>1,1,proportions$prop_of_religion)
proportions$prop_of_religion <- ifelse(proportions$prop_of_religion<0,0,proportions$prop_of_religion)

proportions$prop_of_sport <- ifelse(proportions$prop_of_sport>1,1,proportions$prop_of_sport)
proportions$prop_of_sport <- ifelse(proportions$prop_of_sport<0,0,proportions$prop_of_sport)

proportions$prop_of_weather <- ifelse(proportions$prop_of_weather>1,1,proportions$prop_of_weather)
proportions$prop_of_weather <- ifelse(proportions$prop_of_weather<0,0,proportions$prop_of_weather)

head(proportions)

```


```{r examine correlations, echo=TRUE, warning=FALSE, message=FALSE, error=FALSE, cache = TRUE}

#examine the correlations
proportions_for_clustering <- proportions[,c(2:3,20:35)]
ggpairs(proportions_for_clustering, columns = 1:18) #no variables are perfectly correlated, no need to remove variables

```


### 2.2. We determine the ideal number of clusters by computing the inter-cluster SSE per number of clusters

```{r sse within cluster by number of cluster, echo=TRUE, warning=FALSE, message=FALSE, error=FALSE, cache=TRUE, results=FALSE}
set.seed(123)

#compute within cluster sum of square 
wss <- function(k) {
  kmeans(proportions_for_clustering, k, nstart = 10 )$tot.withinss
}

#plot the sse by nu;ber of clusters between 1 and 15
k.values <- 1:15

wss_values <- map_dbl(k.values, wss)
```

```{r plot of sse, echo=TRUE, warning=FALSE, message=FALSE, error=FALSE, cache=TRUE}
plot(k.values, wss_values,
       type="b", pch = 19, frame = FALSE, 
       xlab="Number of clusters K",
       ylab="Total within-clusters sum of squares")

```

```{r plot clusters for different number of clusters, echo=TRUE, warning=FALSE, message=FALSE, error=FALSE, cache=TRUE}
#set number of clusters
k2 <- kmeans(proportions_for_clustering, centers = 3, nstart = 25)
k3 <- kmeans(proportions_for_clustering, centers = 4, nstart = 25)
k4 <- kmeans(proportions_for_clustering, centers = 5, nstart = 25)
k5 <- kmeans(proportions_for_clustering, centers = 6, nstart = 25)

#create plots to compare
p1 <- fviz_cluster(k2, geom = "point", data = proportions_for_clustering) + ggtitle("k = 3")
p2 <- fviz_cluster(k3, geom = "point",  data = proportions_for_clustering) + ggtitle("k = 4")
p3 <- fviz_cluster(k4, geom = "point",  data = proportions_for_clustering) + ggtitle("k = 5")
p4 <- fviz_cluster(k5, geom = "point",  data = proportions_for_clustering) + ggtitle("k = 6")
grid.arrange(p1, p2, p3, p4, nrow = 2)
```

### 2.3. Finally, once the ideal number of clusters determined (5), we plot the distance of each cluster's center to the variables' centers

```{r examine the centers, echo=TRUE, warning=FALSE, message=FALSE, error=FALSE, cache=TRUE, results=FALSE}
#examine the distance to the center of the variables for each cluster
res_kmeans <- cluster_analysis(proportions_for_clustering,
                 n = 5,
                 method = "kmeans")

#compute the centers
predict(res_kmeans)
```


```{r plot examine the centers, echo=TRUE, warning=FALSE, message=FALSE, error=FALSE, cache = TRUE}
#plot the centers
plot(summary(res_kmeans))
```

## 3. Predictive modelling

### 3.1. We compute the average number of shows and time viewed by users in February who already watched a show in January

```{r average shows and time in feb for both month users, echo=TRUE, warning=FALSE, message=FALSE, error=FALSE, cache = TRUE}

#group users by month
users_by_month <- iplayer_data_raw_no_nas %>%
  group_by(user_id, month_of_the_year) %>% 
  summarise(count = n_distinct(program_id), sum(time_viewed_min_enriched))
names(users_by_month)[2] <- "month"

users_by_month$month <- as.integer(users_by_month$month)
names(users_by_month)[3:4] <- c("programs_watched","time_viewed")

#sum the months
users_summed_months <- users_by_month %>%
  group_by(user_id) %>% 
  summarise(sum(month))
names(users_summed_months)[2] <- "months"

#filter for users of both january and february
users_both_month <- subset(users_summed_months, months == 3)

#filter for users of january
users_jan <- subset(users_summed_months, months == 1)

#list the users of only january and both january and february
no_users_jan = data.frame(n_distinct(users_jan$user_id))
no_users_both_month = data.frame(n_distinct(users_both_month$user_id))

#filter for users of both month
vect_users_jan_and_feb <- as.vector(users_both_month$user_id)
users_jan_and_feb <- filter(users_by_month, user_id %in% vect_users_jan_and_feb)

#users who watched a program in January and in February
users_jan_and_feb_feb_data <- subset(users_jan_and_feb, month == 2)

head(users_jan_and_feb_feb_data)

#average of program watched in february by users who watched a program in january
av_both_month_feb_prog_watched <- mean(users_jan_and_feb_feb_data$programs_watched)
av_both_month_feb_prog_watched

#average of time viewed in february by users who watched a program in january
av_both_month_feb_time_viewed <- mean(users_jan_and_feb_feb_data$time_viewed)
av_both_month_feb_time_viewed

```


### 3.2. We create a logistic regression model to predict which users who saw a show in January will again see a show in February

```{r create a binary variable, echo=TRUE, warning=FALSE, message=FALSE, error=FALSE, cache = TRUE}

#filter for users that watched a program only in january to get rid of users who only watched a program in february
users_jan <- as.vector(shows_by_user$user_id)
user_summed_months_filtered_with_jan_users<- filter(users_summed_months, user_id %in% users_jan)

#create the data for our logistic regression
log_reg_data <- cbind(proportions$user_id, proportions_for_clustering, user_summed_months_filtered_with_jan_users$months)
names(log_reg_data)[1] <- "user_id"

#create binary variables to identify users who watched a program both in january and february to run a logistic regression
log_reg_data$watched_again = ifelse(log_reg_data$`user_summed_months_filtered_with_jan_users$months` == 3,1,0)

#get rid of sum of months
log_reg_data <- subset(log_reg_data, select = -20 )

head(log_reg_data)

```

```{r run the logistic regression, echo=TRUE, warning=FALSE, message=FALSE, error=FALSE, cache = TRUE}

#create a sample of the data
log_reg_data_no_id <- subset(log_reg_data, select = -1)

#select 60% of the sample
smp_size <- floor(0.6 * nrow(log_reg_data_no_id))

#set a seed to make the sample reproductible
set.seed(456)
train_ind <- sample(seq_len(nrow(log_reg_data_no_id)), size = smp_size)

#assign the training and the testing datasets to new dfs
train_log_reg <- log_reg_data_no_id[train_ind, ]
test_log_reg <- log_reg_data_no_id[-train_ind, ]

#train our logistic regression on the training dataset
logistic_reg <- glm(watched_again ~ .,
                    data = train_log_reg)
summary(logistic_reg)

#predict with our model on the testing dataset
predict_log_reg <- predict(logistic_reg, newdata = test_log_reg, type = "response", family = binomial)

#create a ROC curve
predict_log_reg_df <- data.frame(predict_log_reg)

ROC_logreg <- cbind(test_log_reg$watched_again,predict_log_reg_df)
ROC_logreg_clean <- na.omit(ROC_logreg)
names(ROC_logreg_clean)[1] <- "actual"

PRROC_obj <- roc.curve(scores.class0 = ROC_logreg_clean$predict_log_reg, weights.class0=ROC_logreg_clean$actual,
                       curve=TRUE)
PRROC_obj
plot(PRROC_obj)
abline(v = 0.58, col="blue", lty=5)
abline(v = 1.14, col="red", lty=7)
legend("topleft", legend=c("Biggest vert. dist."),
       col=c("blue"), lty=5, cex=0.6)
legend("topright", legend=c("Chosen cut-off"),
       col=c("red"), lty=5, cex=0.6)

#examine the confusion matrices to determine the best cut-off 

cut_off_function <- function(x){
pred_log_reg_cut_off <- ifelse(predict_log_reg_df$predict_log_reg > x,1,0)
table(test_log_reg$watched_again, pred_log_reg_cut_off)
}

#test for different cut-offs
cut_off_function(0.05)
cut_off_function(0.1)
cut_off_function(0.15)
cut_off_function(0.2)
cut_off_function(0.25)
cut_off_function(0.3)
cut_off_function(0.35)
cut_off_function(0.4)
cut_off_function(0.425)
cut_off_function(0.45)
cut_off_function(0.475)
cut_off_function(0.5)
cut_off_function(0.525)
cut_off_function(0.55)
cut_off_function(0.6)
cut_off_function(0.65)
cut_off_function(0.7)

#the best cut-off is 0.45
pred_log_reg_cut_off_0_45 <- data.frame(ifelse(predict_log_reg_df$predict_log_reg > 0.45,1,0))

```

### 3.3. We create a linear regression model to determine how many shows and how many minutes users who watched a show in January will watch again in February

```{r prepare data for linear regression, echo=TRUE, warning=FALSE, message=FALSE, error=FALSE, cache = TRUE}

#small discrepancy in the number of rows between our list of users that watched in january and february and the proportions we computed for each user (only 10 rows) -> we filter out the 10 missing id users
lin_reg_data <- subset(log_reg_data, watched_again == 1)
lig_red_data_id <- as.vector(lin_reg_data$user_id)

users_jan_and_feb_feb_data_cleared <- filter(users_jan_and_feb_feb_data, user_id  %in% lig_red_data_id)
names(users_jan_and_feb_feb_data_cleared)[3:4] <- c("shows_watched_feb","time_viewed_feb")

#create the data for our linear regression
lin_reg_data_complete <- cbind(lin_reg_data, users_jan_and_feb_feb_data_cleared$shows_watched_feb, users_jan_and_feb_feb_data_cleared$time_viewed_feb)

names(lin_reg_data_complete)[21:22] <- c("shows_watched_feb","time_viewed_feb")

head(lin_reg_data_complete)

#examine the correlation of our variables
lin_reg_data_complete_corr_analysis <- lin_reg_data_complete[2:22]

ggpairs(lin_reg_data_complete_corr_analysis) #no variables are perfectly correlated, no need to remove variables

```

```{r run the linear regression, echo=TRUE, warning=FALSE, message=FALSE, error=FALSE, cache = TRUE}

#create a sample of the data
set.seed(789)

#select 60% of the sample
smp_size_lin_reg <- floor(0.6 * nrow(lin_reg_data_complete))
train_ind2 <- sample(seq_len(nrow(lin_reg_data_complete)), size = smp_size_lin_reg)

#assign the training and the testing datasets to new dfs
train_lin_reg <- lin_reg_data_complete[train_ind2, ]
test_lin_reg <- lin_reg_data_complete[-train_ind2, ]

#train our linear regression for shows watched on the training dataset
lin_reg_shows_watched <- lm(shows_watched ~
                              prop_watched_during_weekend +
                              prop_of_engagement +
                              prop_of_D + prop_of_E + prop_of_N +
                              prop_of_children + prop_of_comedy + prop_of_drama + prop_of_entertainment + prop_of_factual + prop_of_learning + prop_of_music + prop_of_news + prop_of_religion + prop_of_sport + prop_of_weather,
                              data = train_lin_reg)
summary(lin_reg_shows_watched)

#predict the testing dataset with our linear regression of shows watched
predict_shows_watched <- data.frame(predict(lin_reg_shows_watched, test_lin_reg))
sse_predict_shows_table <- data.frame(cbind(test_lin_reg$user_id,predict_shows_watched$predict.lin_reg_shows_watched..test_lin_reg.,test_lin_reg$shows_watched))
names(sse_predict_shows_table)[1:3] <- c("user_id","predicted_shows","actual_shows")

#compute the sse for our linear regression of shows watched
sse_predict_shows_table$predicted_shows <- as.numeric(sse_predict_shows_table$predicted_shows)
sse_predict_shows_table$actual_shows <- as.numeric(sse_predict_shows_table$actual_shows)
sse_predict_shows_table$predicted_shows <- ifelse(sse_predict_shows_table$predicted_shows<0,0,sse_predict_shows_table$predicted_shows)
sse_predict_shows_table$sse <- (sse_predict_shows_table$actual_shows - sse_predict_shows_table$predicted_shows) ^ 2
sse_predict_shows <- sum(sse_predict_shows_table$sse)
sse_predict_shows

#train our linear regression for time viewed on the training dataset
lin_reg_time_viewed <- lm(time_viewed_enriched ~
                              prop_watched_during_weekend +
                              prop_of_engagement +
                              prop_of_D + prop_of_E + prop_of_N +
                              prop_of_children + prop_of_comedy + prop_of_drama + prop_of_entertainment + prop_of_factual + prop_of_learning + prop_of_music + prop_of_news + prop_of_religion + prop_of_sport + prop_of_weather,
                              data = train_lin_reg)
summary(lin_reg_time_viewed)

#predict the testing dataset with our linear regression of time viewed
predict_time_viewed <- data.frame(predict(lin_reg_time_viewed, test_lin_reg))
sse_predict_time_table <- data.frame(cbind(test_lin_reg$user_id,predict_time_viewed$predict.lin_reg_time_viewed..test_lin_reg.,test_lin_reg$time_viewed_enriched))
names(sse_predict_time_table)[1:3] <- c("user_id","predicted_time","actual_time")

#compute the sse for our linear regression of time viewed
sse_predict_time_table$predicted_time <- as.numeric(sse_predict_time_table$predicted_time)
sse_predict_time_table$actual_time <- as.numeric(sse_predict_time_table$actual_time)
sse_predict_time_table$predicted_time <- ifelse(sse_predict_time_table$predicted_time<0,0,sse_predict_time_table$predicted_time)
sse_predict_time_table$sse <- (sse_predict_time_table$actual_time - sse_predict_time_table$predicted_time) ^ 2
sse_predict_time <- sum(sse_predict_time_table$sse)
sse_predict_time

```

Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.
